{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biodiversity in National Parks\n",
    "Jonathan Bitner | Started 3/11/2024\\\n",
    "Codecademy portfolio project\\\n",
    "My goal is to showcase my thought process when looking at the data and explain each decision I make.\\\n",
    "For questions or comments, email at jsbitner94@gmail.com\n",
    "\n",
    "### Project description from Codecademy:\n",
    "For this project, you will interpret data from the National Parks Service about endangered species in different parks.\\\n",
    "You will perform some data analysis on the conservation statuses of these species and investigate if there are any patterns or themes to the types of species that become endangered.\\\n",
    "During this project, you will analyze, clean up, and plot data as well as pose questions and seek to answer them in \n",
    "a meaningful way.\\\n",
    "After you perform your analysis, you will share your findings about the National Park Service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Outline:\n",
    "* Review data in `observations.csv` and `species_info.csv`\n",
    "* Determine project goals\n",
    "* Explore and explain data; consider analytical steps required\n",
    "* Format for presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Review the data\n",
    "\n",
    "### Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, chi2_contingency\n",
    "\n",
    "observations_csv = pd.read_csv(r'C:\\Users\\jsbit\\OneDrive\\Documents\\Coding 2023\\Git\\national-parks-biodiversity\\observations.csv', encoding_errors='replace')\n",
    "species_info_csv = pd.read_csv(r'C:\\Users\\jsbit\\OneDrive\\Documents\\Coding 2023\\Git\\national-parks-biodiversity\\species_info.csv', encoding_errors='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics\n",
    "#### Descriptives for `observations_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five rows:\n",
      "             scientific_name                            park_name  observations\n",
      "0        Vicia benghalensis  Great Smoky Mountains National Park            68\n",
      "1            Neovison vison  Great Smoky Mountains National Park            77\n",
      "2         Prunus subcordata               Yosemite National Park           138\n",
      "3      Abutilon theophrasti                  Bryce National Park            84\n",
      "4  Githopsis specularioides  Great Smoky Mountains National Park            85\n",
      "\n",
      "Column names:\n",
      " Index(['scientific_name', 'park_name', 'observations'], dtype='object') \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23296 entries, 0 to 23295\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   scientific_name  23296 non-null  object\n",
      " 1   park_name        23296 non-null  object\n",
      " 2   observations     23296 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 546.1+ KB\n",
      "None\n",
      "\n",
      "Description:\n",
      "          scientific_name                            park_name  observations\n",
      "count              23296                                23296  23296.000000\n",
      "unique              5541                                    4           NaN\n",
      "top     Myotis lucifugus  Great Smoky Mountains National Park           NaN\n",
      "freq                  12                                 5824           NaN\n",
      "mean                 NaN                                  NaN    142.287904\n",
      "std                  NaN                                  NaN     69.890532\n",
      "min                  NaN                                  NaN      9.000000\n",
      "25%                  NaN                                  NaN     86.000000\n",
      "50%                  NaN                                  NaN    124.000000\n",
      "75%                  NaN                                  NaN    195.000000\n",
      "max                  NaN                                  NaN    321.000000\n"
     ]
    }
   ],
   "source": [
    "print('First five rows:\\n', observations_csv.head())\n",
    "print('\\nColumn names:\\n', observations_csv.columns, '\\n\\nInfo:')\n",
    "print(observations_csv.info())\n",
    "print('\\nDescription:\\n', observations_csv.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial observations\n",
    "* Curious if all `park_name` values end in `National Park`\n",
    "* Column names are approptiately named and formatted (lowercase, underscore_for_space, no whitespace)\n",
    "* No missing data on initial inspection\n",
    "* Data types are appropriate\n",
    "* Surprised to see the large amount of data for only four national parks\n",
    "    * Potential to change `park_name` to Categorical\n",
    "\n",
    "#### Descriptives for `species_info_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five rows:\n",
      "   category                scientific_name  \\\n",
      "0   Mammal  Clethrionomys gapperi gapperi   \n",
      "1   Mammal                      Bos bison   \n",
      "2   Mammal                     Bos taurus   \n",
      "3   Mammal                     Ovis aries   \n",
      "4   Mammal                 Cervus elaphus   \n",
      "\n",
      "                                        common_names conservation_status  \n",
      "0                           Gapper's Red-Backed Vole                 NaN  \n",
      "1                              American Bison, Bison                 NaN  \n",
      "2  Aurochs, Aurochs, Domestic Cattle (Feral), Dom...                 NaN  \n",
      "3  Domestic Sheep, Mouflon, Red Sheep, Sheep (Feral)                 NaN  \n",
      "4                                      Wapiti Or Elk                 NaN  \n",
      "\n",
      "Column names:\n",
      " Index(['category', 'scientific_name', 'common_names', 'conservation_status'], dtype='object') \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5824 entries, 0 to 5823\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   category             5824 non-null   object\n",
      " 1   scientific_name      5824 non-null   object\n",
      " 2   common_names         5824 non-null   object\n",
      " 3   conservation_status  191 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 182.1+ KB\n",
      "None\n",
      "\n",
      "Description:\n",
      "               category    scientific_name        common_names  \\\n",
      "count             5824               5824                5824   \n",
      "unique               7               5541                5504   \n",
      "top     Vascular Plant  Castor canadensis  Brachythecium Moss   \n",
      "freq              4470                  3                   7   \n",
      "\n",
      "       conservation_status  \n",
      "count                  191  \n",
      "unique                   4  \n",
      "top     Species of Concern  \n",
      "freq                   161  \n"
     ]
    }
   ],
   "source": [
    "print('First five rows:\\n', species_info_csv.head())\n",
    "print('\\nColumn names:\\n', species_info_csv.columns, '\\n\\nInfo:')\n",
    "print(species_info_csv.info())\n",
    "print('\\nDescription:\\n', species_info_csv.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial observations\n",
    "* I had the impression I would be working with trees; good to know that this must contain all life in the national parks.\n",
    "* Could encounter difficulties with length of `common_names` due to multiple entries in a single observation\n",
    "* Columns are appropriately named and formatted\n",
    "* Data types are approptiate\n",
    "    * Potential to change `category` to Categorical, since there are only seven unique values\n",
    "    * Same for `conservation_status`; four unique values\n",
    "* Only `conservation_status` is missing values\n",
    "    * Are values only included for endangered species?\n",
    "    * It seems worth exploring endangered species further\n",
    "* I am surprised to see that the `count` and `unique` values are not the same for `scientific_name` and `common_names`\n",
    "    * Indicates that there are duplicates of some kind here\n",
    "    * Could a species be listed as `endangered` in one region, but not another, resulting in separate rows? Unlikely, since this dataset is not connected to `observations_csv` and has no park or region-related information.\n",
    "    * Could there be multiple choices for `common_names`? Unlikely, since there can be multiple names in `common_names`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Project goals\n",
    "### Personal goals\n",
    "* My main goal in this project is to take a deep dive into everything I learned:\n",
    "    * Data tidying/wrangling\n",
    "    * Determine what visualizations fit the data best\n",
    "    * Ask questions about the data and provide answers\n",
    "    * Format results into a presentable product\n",
    "* _Note:_ The purpose of this document is to showcase my thought process.\n",
    "    * It may look out of order, because I may think of things later\n",
    "    * It will be blocky as I try to process small chunks at a time\n",
    "    * I plan to create a separate document that will organize everything into a more readable document\n",
    "    \n",
    "### Project directions\n",
    "* Initial questions (brainstorming - will select questions later):\n",
    "    * What are the four parks in this dataset?\n",
    "        * Where are they located?\n",
    "        * How much area do they cover?\n",
    "        * When were they founded?\n",
    "        * What was the level of human interaction before founding?\n",
    "        * What is the current level of human impact? (example: direct impact, such as visitors, and indirect impact, such as climate change) \n",
    "        * Can I extrapolate data from these parks to other national parks (Are these good representations of the other ~60 parks?\n",
    "    * What is the distribution of species in the national parks?\n",
    "        * Which park has more endangered species?\n",
    "        * What is the proportion of endangered species versus other?\n",
    "        * Which parks stand out as having significantly more of one species/category?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Data wrangling and tidying\n",
    "Since the `observations_csv` seems to contain the meat of the data, I will start there.\n",
    "\n",
    "### Preliminary data cleaning\n",
    "\n",
    "* Already completed preliminary data cleaning with `.info()` and `.describe(include='all')`\n",
    "\n",
    "### Checking for duplicates\n",
    "#### Duplicates in `observations_csv.scientific_name`\n",
    "* Given that there are 23,296 observations, splitting it between four parks should result in no fewer than 5,824 unique values for `scientific_name`, but there are 5,541 unique values, indicating duplicates.\n",
    "* Maybe I don't quite understand what `observations` means\n",
    "    * I assumed it was all of the instances a given species was found during a certain time-period\n",
    "    * Maybe it could represent (for example) six different researchers covering unique areas of the park submitting their own reports, resulting in overlap on the same species within that park?\n",
    "    * Either way, warrants further investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows when grouped by 'scientific_name':\n",
      "         scientific_name  park_name  observations\n",
      "0         Abies bifolia          4             4\n",
      "1        Abies concolor          4             4\n",
      "2         Abies fraseri          4             4\n",
      "3  Abietinella abietina          4             4\n",
      "4     Abronia ammophila          4             4\n",
      "\n",
      "Length of above grouped df: \n",
      " 5541\n",
      "\n",
      "Duplicates in column for park_name:\n",
      " park_name\n",
      "4     5267\n",
      "8      265\n",
      "12       9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duplicates in column for observations:\n",
      " observations\n",
      "4     5267\n",
      "8      265\n",
      "12       9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Length of series containing duplicate rows:\n",
      " 274\n",
      "\n",
      "First few rows of duplicate rows as dataframe:\n",
      "         scientific_name                            park_name  observations\n",
      "0   Agrostis capillaris                  Bryce National Park           103\n",
      "1   Agrostis capillaris                  Bryce National Park           105\n",
      "2   Agrostis capillaris  Great Smoky Mountains National Park            84\n",
      "3   Agrostis capillaris  Great Smoky Mountains National Park            97\n",
      "4   Agrostis capillaris            Yellowstone National Park           241\n",
      "5   Agrostis capillaris            Yellowstone National Park           267\n",
      "6   Agrostis capillaris               Yosemite National Park           182\n",
      "7   Agrostis capillaris               Yosemite National Park           140\n",
      "8     Agrostis gigantea                  Bryce National Park           104\n",
      "9     Agrostis gigantea                  Bryce National Park           116\n",
      "10    Agrostis gigantea  Great Smoky Mountains National Park            93\n",
      "11    Agrostis gigantea  Great Smoky Mountains National Park            57\n",
      "12    Agrostis gigantea            Yellowstone National Park           253\n",
      "13    Agrostis gigantea            Yellowstone National Park           235\n",
      "14    Agrostis gigantea               Yosemite National Park           148\n",
      "15    Agrostis gigantea               Yosemite National Park           128\n",
      "\n",
      "First few rows of dataframe containing sorted duplicates from species_info_csv:\n",
      "            category      scientific_name  \\\n",
      "193  Vascular Plant  Agrostis capillaris   \n",
      "539  Vascular Plant  Agrostis capillaris   \n",
      "194  Vascular Plant    Agrostis gigantea   \n",
      "540  Vascular Plant    Agrostis gigantea   \n",
      "195  Vascular Plant   Agrostis mertensii   \n",
      "415  Vascular Plant   Agrostis mertensii   \n",
      "196  Vascular Plant      Agrostis scabra   \n",
      "541  Vascular Plant      Agrostis scabra   \n",
      "\n",
      "                                 common_names conservation_status  \n",
      "193                         Rhode Island Bent                 NaN  \n",
      "539         Colonial Bent, Colonial Bentgrass                 NaN  \n",
      "194                                    Redtop                 NaN  \n",
      "540       Black Bent, Redtop, Water Bentgrass                 NaN  \n",
      "195                         Northern Agrostis                 NaN  \n",
      "415      Arctic Bentgrass, Northern Bentgrass                 NaN  \n",
      "196          Rough Bentgrass, Rough Hairgrass                 NaN  \n",
      "541  Rough Bent, Rough Bentgrass, Ticklegrass                 NaN  \n"
     ]
    }
   ],
   "source": [
    "# First, I will sort the data by 'scientific_name', and look at the first few instances of duplicates.\n",
    "sorted_observations_csv = observations_csv.sort_values(by=['scientific_name', 'park_name'])\n",
    "# print(sorted_observations_csv.head(20))\n",
    "\n",
    "# Ok that didn't work like I had hoped. \n",
    "# Instead, I will:\n",
    "    # Group by scientific name\n",
    "    # Filter for results greater than four\n",
    "grouped_observations_csv = observations_csv.groupby('scientific_name').count().reset_index()\n",
    "print('First few rows when grouped by \\'scientific_name\\':\\n', grouped_observations_csv.head())\n",
    "print('\\nLength of above grouped df: \\n', len(grouped_observations_csv)) # Checking that there are still 5,541 unique observations (there are)\n",
    "# Seeing how many duplicates there are for 'park_name' and 'observations'; I hope they match\n",
    "print('\\nDuplicates in column for park_name:\\n', grouped_observations_csv.park_name.value_counts())\n",
    "print('\\nDuplicates in column for observations:\\n', grouped_observations_csv.observations.value_counts())\n",
    "# I find these results interesting: \n",
    "    # Eight observations for a species found 265 times, and twelve found nine times\n",
    "    # These are in multiples of four, so they are likely duplicated evenly across the parks\n",
    "    \n",
    "# Gathering a list of 'scientific_names' to filter 'observations_csv' using '.isin()'\n",
    "duplicated_observations_list = grouped_observations_csv.scientific_name[grouped_observations_csv['observations'] > 4].reset_index(drop=True) \n",
    "print('\\nLength of series containing duplicate rows:\\n', len(duplicated_observations_list)) # Expecting 274 (265+7 from 'value_counts' above that were greater than four) # Output 274\n",
    "duplicated_observations_df = observations_csv[observations_csv.scientific_name.isin(duplicated_observations_list)].sort_values(\n",
    "    by=['scientific_name', 'park_name']).reset_index(drop=True)\n",
    "\n",
    "# Investigating duplicates\n",
    "print('\\nFirst few rows of duplicate rows as dataframe:\\n', duplicated_observations_df.head(16)) # Still no answers, try unique 'scientific_name' for trends or patterns?\n",
    "# print(duplicated_observations_df.scientific_name.unique()) # No obvious trends, maybe also check category?\n",
    "duplicated_observations_species_info = species_info_csv[species_info_csv.scientific_name.isin(duplicated_observations_list)].reset_index(drop=True)\n",
    "# print(duplicated_observations_species_info.head())\n",
    "# print(duplicated_observations_species_info.scientific_name.value_counts().head(20))\n",
    "\n",
    "# Initial answer: There are nine triple duplicates of 'scientific_name' in 'species_info_csv', and 265 double duplicates.\n",
    "# Why is that?\n",
    "sorted_dup_spec_info_df = duplicated_observations_species_info.sort_values(by=['scientific_name', 'category'])\n",
    "print('\\nFirst few rows of dataframe containing sorted duplicates from species_info_csv:\\n', sorted_dup_spec_info_df.head(8))\n",
    "# I see that there are duplicate 'scientific_name' values, but the corresponding 'common_names' are mostly different, but still very similar\n",
    "    # For example, both 'common_names' rows for 'Agrostis gigantea' contain 'Redtop', but the second row contains more names.\n",
    "    # Is there a way I can merge these together, but only keep unique 'common_names'?\n",
    "    # Are we supposed to just 'know' which 'scientific_name' from 'observations_csv' is supposed to match up with the same column/row in 'species_info_csv'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22164\n",
      "   scientific_name                            park_name  observations\n",
      "0    Abies bifolia                  Bryce National Park           109\n",
      "1    Abies bifolia  Great Smoky Mountains National Park            72\n",
      "2    Abies bifolia            Yellowstone National Park           215\n",
      "3    Abies bifolia               Yosemite National Park           136\n",
      "4   Abies concolor                  Bryce National Park            83\n",
      "5   Abies concolor  Great Smoky Mountains National Park           101\n",
      "6   Abies concolor            Yellowstone National Park           241\n",
      "7   Abies concolor               Yosemite National Park           205\n",
      "8    Abies fraseri                  Bryce National Park           109\n",
      "9    Abies fraseri  Great Smoky Mountains National Park            81\n",
      "10   Abies fraseri            Yellowstone National Park           218\n",
      "11   Abies fraseri               Yosemite National Park           110\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicates in 'observations_csv'\n",
    "    # I would love to take care of duplicates in 'species_info_csv', but with my current skills that could take me a while, \n",
    "    # and I want to stay focused and finish in a reasonable time.\n",
    "    \n",
    "observations_csv_no_duplicates = observations_csv.groupby(by=['scientific_name', 'park_name'], as_index=False).observations.sum()\n",
    "# I want len(observations_csv_no_duplicates) == 22,164\n",
    "    # Referencing above output for 'Duplicates in column for (park_name & observations):'\n",
    "    # Previously, 4*5267 + 8*265 + 12*9 = 23,296, the total number of rows in observations_csv\n",
    "    # If duplicates are removed, there should only be 4 of each item\n",
    "    # New would look like 4*5267 + 4*265 + 4*9, or 4*5541, the number of unique values\n",
    "    # New math indicates there should be 22,164 rows after removing duplicates\n",
    "print(len(observations_csv_no_duplicates)) # Is 22,164\n",
    "print(observations_csv_no_duplicates.head(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicates in `species_info_csv`\n",
    "Will come back here if there is time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More tidying\n",
    "* Columns named appropriately\n",
    "* Data types approptiate\n",
    "* No need to parse strings or split columns\n",
    "* No missing data\n",
    "* No need to fix columns with `.melt()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
